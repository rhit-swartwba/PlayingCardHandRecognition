{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7359b1a1-90e3-4e14-ac6d-1d7d93f06afa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ultralytics'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ultralytics'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "import os\n",
    "import random "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1262d934-7dfe-4fff-9f02-1fbf9d3d6e13",
   "metadata": {},
   "source": [
    "### Preliminary tests/book-keeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "737133ed-97a3-4380-ab03-39bb9bf399ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['10c', '10d', '10h', '10s', '2c', '2d', '2h', '2s', '3c', '3d', '3h', '3s', '4c', '4d', '4h', '4s', '5c', '5d', '5h', '5s', '6c', '6d', '6h', '6s', '7c', '7d', '7h', '7s', '8c', '8d', '8h', '8s', '9c', '9d', '9h', '9s', 'Ac', 'Ad', 'Ah', 'As', 'Jc', 'Jd', 'Jh', 'Js', 'Kc', 'Kd', 'Kh', 'Ks', 'Qc', 'Qd', 'Qh', 'Qs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc7ca7da-6e57-42a2-8712-4d62d6125273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful functions\n",
    "def IMGwBB(class_names, image_dir, label_dir, subplot_size):\n",
    "    image_files = os.listdir(image_dir)[:9]\n",
    "    label_files = []\n",
    "\n",
    "    for i in range(len(image_files)):\n",
    "        label_files.append(image_files[i].replace('.jpg', '.txt'))\n",
    "\n",
    "    \n",
    "    sp_r, sp_c = subplot_size\n",
    "    fig, axes = plt.subplots(sp_r, sp_c,figsize=(12,12))\n",
    "    axes = axes.ravel()\n",
    "        \n",
    "    for i in range(len(image_files)):     \n",
    "        img_path = os.path.join(image_dir, image_files[i])\n",
    "        label_path = os.path.join(label_dir, label_files[i])\n",
    "        \n",
    "        \n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        height, width, _ = img.shape\n",
    "    \n",
    "        with open(label_path, \"r\") as f:\n",
    "            labels = f.readlines()\n",
    "    \n",
    "        for label in labels:\n",
    "            cid, xc, yc, w, h = map(float, label.split())\n",
    "            x1 = int((xc - w / 2) * width)\n",
    "            y1 = int((yc - h / 2) * height)\n",
    "            x2 = int((xc + w / 2) * width)\n",
    "            y2 = int((yc + h / 2) * height)\n",
    "    \n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 255, 0), 2)\n",
    "            cv2.putText(img, str(class_names[int(cid)]), (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6,(255, 255, 0), 2)\n",
    "        \n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(f'Image: {i + 1}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc8c74d2-7efb-4384-b01c-46db92150e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_stats(class_names, label_dir):\n",
    "    label_files = os.listdir(label_dir)\n",
    "    nc = len(class_names) # number of classes\n",
    "    class_counts = [0] * nc\n",
    "    \n",
    "    for i in range(len(label_files)):     \n",
    "        label_path = os.path.join(label_dir, label_files[i])\n",
    "        # img_path = os.path.join('./yolo_data/train/images/', label_files[0].replace('.txt', '.jpg'))\n",
    "\n",
    "        # img = cv2.imread(img_path)\n",
    "        # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        # height, width, _ = img.shape\n",
    "        # plt.imshow(img)\n",
    "        \n",
    "        with open(label_path, \"r\") as f:\n",
    "            labels = f.readlines()\n",
    "\n",
    "        for label in labels: \n",
    "            cid, xc, yc, w, h = map(float, label.split())\n",
    "            cid = int(cid)\n",
    "            class_counts[cid] += 1\n",
    "\n",
    "    max_id = np.argmax(class_counts)\n",
    "    max_count = class_counts[max_id]\n",
    "    max_class = class_names[max_id]\n",
    "\n",
    "    min_id = np.argmin(class_counts)\n",
    "    min_count = class_counts[min_id]\n",
    "    min_class = class_names[min_id]\n",
    "\n",
    "    # based on number (ignore suits):\n",
    "    class_counts_ns = [0] * (nc//4)\n",
    "    for i in range(0, nc, 4):\n",
    "        class_counts_ns[i//4] = np.sum(class_counts[i:i+4])\n",
    "    \n",
    "    \n",
    "    print(f'Class count list: {class_counts}')\n",
    "    print(f'Class count list (no suits): {class_counts_ns}')\n",
    "    \n",
    "    max_id_ns = np.argmax(class_counts_ns)\n",
    "    max_count_ns = class_counts_ns[max_id_ns]\n",
    "    max_class_ns = class_names[max_id_ns * 4][:-1]\n",
    "\n",
    "    min_id_ns = np.argmin(class_counts_ns)\n",
    "    min_count_ns = class_counts_ns[min_id_ns]\n",
    "    min_class_ns = class_names[min_id_ns * 4][:-1]\n",
    "\n",
    "    total_cards = np.sum(class_counts)\n",
    "    baseline_error = (total_cards - max_count) * 100 / total_cards\n",
    "    baseline_error_ns  = (total_cards - max_count_ns) * 100 / total_cards\n",
    "    print(f'total cards: {total_cards}')\n",
    "    print(f'max card: {max_class}\\t count: {max_count}')\n",
    "    print(f'min card: {min_class}\\t count: {min_count}')\n",
    "\n",
    "    print(f'max card (no suits): {max_class_ns}\\t count: {max_count_ns}')\n",
    "    print(f'min card (no suits): {min_class_ns}\\t count: {min_count_ns}')\n",
    "\n",
    "    print(f'baseline error: {baseline_error}')\n",
    "    print(f'baseline error (no suits): {baseline_error_ns}')\n",
    "\n",
    "    return class_counts, class_counts_ns         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5312db68-638f-4534-a8fc-c895aa0f2d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000\n",
      "4000\n",
      "2000\n",
      "\n",
      "TRAIN DATA STATS\n",
      "----------\n",
      "Class count list: [986, 999, 1005, 1032, 1062, 1071, 1046, 955, 1034, 973, 1098, 1066, 985, 997, 1117, 1005, 942, 1001, 1039, 1004, 997, 1039, 993, 1011, 994, 1085, 978, 978, 1012, 1171, 989, 998, 950, 980, 1049, 1006, 1062, 1015, 1028, 1042, 1022, 1075, 971, 1013, 1014, 1014, 1034, 1037, 938, 1050, 1046, 995]\n",
      "Class count list (no suits): [4022, 4134, 4171, 4104, 3986, 4040, 4035, 4170, 3985, 4147, 4081, 4099, 4029]\n",
      "total cards: 53003\n",
      "max card: 8d\t count: 1171\n",
      "min card: Qc\t count: 938\n",
      "max card (no suits): 3\t count: 4171\n",
      "min card (no suits): 9\t count: 3985\n",
      "baseline error: 97.790691092957\n",
      "baseline error (no suits): 92.13063411505009\n",
      "\n",
      "VALIDATION DATA STATS\n",
      "----------\n",
      "Class count list: [282, 290, 322, 250, 295, 259, 294, 299, 308, 250, 313, 358, 276, 282, 312, 295, 290, 283, 253, 281, 284, 286, 329, 289, 304, 311, 303, 304, 285, 261, 255, 339, 309, 275, 272, 263, 288, 294, 283, 322, 265, 285, 278, 282, 307, 304, 297, 264, 300, 317, 295, 317]\n",
      "Class count list (no suits): [1144, 1147, 1229, 1165, 1107, 1188, 1222, 1140, 1119, 1187, 1110, 1172, 1229]\n",
      "total cards: 15159\n",
      "max card: 3s\t count: 358\n",
      "min card: 10s\t count: 250\n",
      "max card (no suits): 3\t count: 1229\n",
      "min card (no suits): 5\t count: 1107\n",
      "baseline error: 97.63836664687645\n",
      "baseline error (no suits): 91.89260505310376\n",
      "\n",
      "TEST DATA STATS\n",
      "----------\n",
      "Class count list: [137, 170, 149, 151, 139, 158, 156, 153, 155, 143, 169, 164, 142, 139, 128, 135, 152, 173, 169, 168, 137, 167, 148, 155, 161, 154, 167, 135, 140, 130, 155, 123, 139, 128, 107, 151, 135, 146, 158, 154, 145, 130, 154, 146, 147, 114, 166, 144, 120, 127, 137, 118]\n",
      "Class count list (no suits): [607, 606, 631, 544, 662, 607, 617, 548, 525, 593, 575, 571, 502]\n",
      "total cards: 7588\n",
      "max card: 5d\t count: 173\n",
      "min card: 9h\t count: 107\n",
      "max card (no suits): 5\t count: 662\n",
      "min card (no suits): Q\t count: 502\n",
      "baseline error: 97.72008434370058\n",
      "baseline error (no suits): 91.27569847127043\n"
     ]
    }
   ],
   "source": [
    "train_img_dir = './datasets/train/images/'\n",
    "train_label_dir = './datasets/train//labels/'\n",
    "\n",
    "val_img_dir = './datasets/valid/images/'\n",
    "val_label_dir = './datasets/valid/labels/'\n",
    "\n",
    "test_img_dir = './datasets/test/images/'\n",
    "test_label_dir = './datasets/test/labels/'\n",
    "\n",
    "print(len(os.listdir(train_img_dir)))\n",
    "print(len(os.listdir(val_img_dir)))\n",
    "print(len(os.listdir(test_img_dir)))\n",
    "\n",
    "# cc, cc_ns = label_stats(class_names, label_dir)\n",
    "# IMGwBB(class_names, image_dir, label_dir, (3,3))\n",
    "print('\\nTRAIN DATA STATS\\n----------')\n",
    "cc, cc_ns = label_stats(class_names, train_label_dir)\n",
    "print('\\nVALIDATION DATA STATS\\n----------')\n",
    "cc, cc_ns = label_stats(class_names, val_label_dir)\n",
    "print('\\nTEST DATA STATS\\n----------')\n",
    "cc, cc_ns = label_stats(class_names, test_label_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9799a9d1-b0fb-4a82-a287-1120621fc9fb",
   "metadata": {},
   "source": [
    "### YOLOv5 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc9bf4bf-b743-4dde-805b-1239a5141b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov5nu.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f94db740-5b63-4a04-b067-bd03b7c9dacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.70 🚀 Python-3.12.8 torch-2.6.0 MPS (Apple M4)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov5nu.pt, data=data.yaml, epochs=3, time=None, patience=100, batch=-1, imgsz=416, save=True, save_period=-1, cache=False, device=mps, workers=0, project=./quick_model, name=quick_model2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=quick_model/quick_model2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1760  ultralytics.nn.modules.conv.Conv             [3, 16, 6, 2, 2]              \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      4800  ultralytics.nn.modules.block.C3              [32, 32, 1]                   \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     29184  ultralytics.nn.modules.block.C3              [64, 64, 2]                   \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  3    156928  ultralytics.nn.modules.block.C3              [128, 128, 3]                 \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1]                 \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 14                  -1  1      8320  ultralytics.nn.modules.conv.Conv             [128, 64, 1, 1]               \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     22912  ultralytics.nn.modules.block.C3              [128, 64, 1, False]           \n",
      " 18                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1     74496  ultralytics.nn.modules.block.C3              [128, 128, 1, False]          \n",
      " 21                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 24        [17, 20, 23]  1    761452  ultralytics.nn.modules.head.Detect           [52, [64, 128, 256]]          \n",
      "YOLOv5n summary: 262 layers, 2,518,604 parameters, 2,518,588 gradients, 7.2 GFLOPs\n",
      "\n",
      "Transferred 427/427 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir quick_model/quick_model2', view at http://localhost:6006/\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/neosim/Developer/Undergraduate/Y4_Senior/CSSE-463/dataset\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=416 at 60.0% CUDA memory utilization.\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0m ⚠️ intended for CUDA devices, using default batch-size 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/neosim/Developer/Undergraduate/Y4_Senior/CSSE-463/dataset\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/neosim/Developer/Undergraduate/Y4_Senior/CSSE-463/datasets/\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to quick_model/quick_model2/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000179, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 416 train, 416 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mquick_model/quick_model2\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3      5.42G      1.058      3.281     0.8657         87        416: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4000      15159      0.093      0.288     0.0861     0.0689\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3      8.08G     0.9522      2.815     0.8527         74        416: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4000      15159       0.19      0.436      0.207      0.169\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3        11G     0.8843      2.473     0.8448         89        416: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4000      15159      0.269      0.517      0.307      0.258\n",
      "\n",
      "3 epochs completed in 0.478 hours.\n",
      "Optimizer stripped from quick_model/quick_model2/weights/last.pt, 5.3MB\n",
      "Optimizer stripped from quick_model/quick_model2/weights/best.pt, 5.3MB\n",
      "\n",
      "Validating quick_model/quick_model2/weights/best.pt...\n",
      "Ultralytics 8.3.70 🚀 Python-3.12.8 torch-2.6.0 MPS (Apple M4)\n",
      "YOLOv5n summary (fused): 193 layers, 2,513,084 parameters, 0 gradients, 7.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4000      15159       0.27      0.516      0.307      0.258\n",
      "                   10c        180        282        0.3      0.805      0.492      0.384\n",
      "                   10d        188        290      0.275      0.645      0.354      0.285\n",
      "                   10h        201        322      0.385      0.674      0.504      0.397\n",
      "                   10s        165        250      0.313       0.88      0.524      0.419\n",
      "                    2c        193        295       0.24      0.536      0.259      0.228\n",
      "                    2d        167        259      0.217      0.432      0.198      0.173\n",
      "                    2h        187        294      0.227      0.112      0.151      0.131\n",
      "                    2s        192        299      0.199      0.475      0.204      0.175\n",
      "                    3c        201        308      0.327      0.769      0.437       0.38\n",
      "                    3d        167        250      0.232       0.32       0.19      0.165\n",
      "                    3h        200        313      0.311      0.463      0.312      0.266\n",
      "                    3s        229        358      0.288      0.735      0.383      0.333\n",
      "                    4c        178        276      0.262      0.728      0.369      0.319\n",
      "                    4d        183        282      0.326      0.677      0.429      0.372\n",
      "                    4h        199        312      0.413      0.106      0.232      0.198\n",
      "                    4s        198        295      0.305      0.773      0.457      0.392\n",
      "                    5c        182        290      0.218      0.286      0.202      0.169\n",
      "                    5d        178        283      0.116      0.106     0.0856     0.0739\n",
      "                    5h        168        253      0.155     0.0949      0.108     0.0907\n",
      "                    5s        194        281      0.175      0.338      0.171      0.145\n",
      "                    6c        183        284      0.203      0.415      0.195      0.166\n",
      "                    6d        185        286      0.229      0.144      0.178      0.156\n",
      "                    6h        210        329      0.188      0.342      0.176      0.152\n",
      "                    6s        185        289       0.14      0.668      0.162      0.138\n",
      "                    7c        196        304      0.477      0.318      0.395       0.32\n",
      "                    7d        192        311      0.431       0.72      0.604      0.512\n",
      "                    7h        201        303      0.238      0.554      0.291      0.241\n",
      "                    7s        195        304      0.332      0.908      0.669      0.568\n",
      "                    8c        184        285      0.307      0.428      0.279       0.24\n",
      "                    8d        170        261       0.16      0.272      0.136      0.118\n",
      "                    8h        173        255      0.504      0.188      0.317      0.274\n",
      "                    8s        218        339      0.259      0.631      0.305      0.266\n",
      "                    9c        199        309      0.219      0.369      0.199      0.172\n",
      "                    9d        183        275      0.173      0.149      0.139      0.122\n",
      "                    9h        178        272      0.208      0.691      0.273      0.241\n",
      "                    9s        176        263      0.212      0.586      0.262      0.229\n",
      "                    Ac        185        288       0.24       0.76      0.411      0.347\n",
      "                    Ad        192        294      0.219      0.299       0.18      0.152\n",
      "                    Ah        192        283      0.362      0.385      0.327      0.278\n",
      "                    As        213        322      0.386      0.826      0.536      0.449\n",
      "                    Jc        178        265      0.219       0.63      0.311      0.252\n",
      "                    Jd        181        285      0.404      0.554      0.431      0.342\n",
      "                    Jh        183        278      0.296      0.374      0.279      0.218\n",
      "                    Js        188        282      0.293      0.844      0.457      0.376\n",
      "                    Kc        196        307      0.319      0.726       0.47      0.396\n",
      "                    Kd        186        304      0.232       0.75      0.285      0.234\n",
      "                    Kh        192        297      0.237      0.593      0.249      0.201\n",
      "                    Ks        166        264       0.21      0.614      0.279      0.234\n",
      "                    Qc        202        300      0.269      0.697      0.318      0.271\n",
      "                    Qd        202        317       0.23      0.511      0.248      0.174\n",
      "                    Qh        189        295      0.238      0.342      0.228      0.197\n",
      "                    Qs        205        317      0.295      0.609      0.329      0.276\n",
      "Speed: 0.2ms preprocess, 1.8ms inference, 0.0ms loss, 9.6ms postprocess per image\n",
      "Results saved to \u001b[1mquick_model/quick_model2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "quick_model = model.train(data = 'data.yaml', \n",
    "                          imgsz = 416,\n",
    "                          epochs=3,\n",
    "                          batch=-1, \n",
    "                          device=\"mps\",\n",
    "                          optimizer = 'auto', \n",
    "                          plots=True, \n",
    "                          verbose=True,\n",
    "                          project='./quick_model',\n",
    "                          name='quick_model'\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7380cb3f-6c8a-4a23-9bcf-4670ced4fccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ultralytics import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe87b900-e17d-4eaf-8a0e-d20d1d2a5a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings.update({\"datasets_dir\": \"/Users/neosim/Developer/Undergraduate/Y4_Senior/CSSE-463/\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c4fa1e-ebca-4b35-9ef5-45b7ce451d65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csse413",
   "language": "python",
   "name": "csse413"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
